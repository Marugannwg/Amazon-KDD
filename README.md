# Amazon-KDD

## Task
Students will work in groups to perform a substantial, multi-modal deep learning project for social insight based on approaches and tools developed/explored over the course of the quarter. These projects must integrate at least **three forms of data** in a single model, and use at least **three types of models** (from three separate weeks over the course of the quarter), and must **validate inferences or predictions** with qualitative interpretation and assessments. These projects are encouraged to be performed in groups (of ~5 students). Examples include (and student groups could pursue one of these examples)â€ : 
* The KDD Cup 2024 provides datasets for various challenges, including (1) simulating and forecasting the behaviors of Amazon users using LLMs and (2) academic text and graph mining. Those interested in text learning, graph learning, social simulation, and the creation of digital doubles using transformers may find these challenges and datasets particularly intriguing. See KDD Cup 2024 pages from Amazon and Tsinghua/Zhipu AI.

Groups will compose: 
1. **Presentation:** Groups will also present the motivation, process and findings from their projects the day before in slots log-proportional to the size of the team (5 minutes/20 slides for 1-person teams; 6.5 minutes/26 slides for 2-person teams; 7.5 minutes/30 slides for 3-person teams; 8 minutes/32 slides for 4-person teams; 8.5 minutes/34 slides for 5-person teams) online Ignite style talks on **Thursday, June 2 from 4:30pm**.
  * Submit (1) final presentation slides by **Thursday, May 23 @ 4:00pm** (for presentations beginning @ 4:30pm to be signed up here).
2. **"Writeup"**: A detailed, entertaining and informative public-facing **Medium.com blog-post** about their projects that includes the motivation, methodological justification and detail, descriptive data and deep learning modeling, interpretation of findings (e.g., discovered structures, predictions, generations), conclusion, and annotated code appendix. These should not read like an academic paper, but a mixture of (1) explanatory tutorial; and (2) digital museum exhibit, balancing intermittent text with figures, description boxes, equations, and/or conceptual diagrams including at least one visual element (e.g., figure, graph, conceptual diagram) for every 300 words of text; and a minimum total of 5000 words and 17 visual elements.
  * **Due Friday, June 3 @ 5pm**.



## Resources:
- Amazon KDD Cup: https://www.aicrowd.com/challenges/amazon-kdd-cup-2024-multi-task-online-shopping-challenge-for-llms
  - Starter Kit repo: https://gitlab.aicrowd.com/aicrowd/challenges/amazon-kdd-cup-2024/amazon-kdd-cup-2024-starter-kit
  - Development data: https://gitlab.aicrowd.com/aicrowd/challenges/amazon-kdd-cup-2024/amazon-kdd-cup-2024-starter-kit/-/blob/master/data/development.json
- Training data (maybe):
  - Webshop: https://github.com/princeton-nlp/webshop
  - An agent benchmark using Webshop: https://github.com/THUDM/AgentBench
- Langchain: https://python.langchain.com/docs/
- Dataset and Instruction: https://gitlab.aicrowd.com/aicrowd/challenges/amazon-kdd-cup-2024/amazon-kdd-cup-2024-starter-kit/-/tree/master

## FAQ
https://discourse.aicrowd.com/t/where-is-the-shopbench-amazon-dataset/9730

## Team Google Drive
[Link here](https://drive.google.com/drive/folders/18EXfDk-9wlKeEkK208alQxfbmMyE2VH4?usp=share_link)
